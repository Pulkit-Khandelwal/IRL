@article{Bellman57,
    author = "Richard Bellman",
     title = "A Markovian Decision Process",
   journal = "Indiana Univ. Math. J.",
  fjournal = "Indiana University Mathematics Journal",
    volume = 6,
      year = 1957,
     issue = 4,
     pages = "679--684",
      issn = "0022-2518",
     coden = "IUMJAB",
   mrclass = "",
}

@article{Watkins92,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Littman94,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Proceedings of the eleventh international conference on machine learning},
  volume={157},
  pages={157--163},
  year={1994}
}

@article{Kaelbling96,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@book{Sutton98,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@inproceedings{Russell98,
  title={Learning agents for uncertain environments},
  author={Russell, Stuart},
  booktitle={Proceedings of the eleventh annual conference on Computational learning theory},
  pages={101--103},
  year={1998},
  organization={ACM}
}

@inproceedings{Ng99,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@inproceedings{Ng00,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  pages={663--670},
  year={2000}
}

@article{Tesauro02,
  title={Pricing in agent economies using multi-agent Q-learning},
  author={Tesauro, Gerald and Kephart, Jeffrey O},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={5},
  number={3},
  pages={289--304},
  year={2002},
  publisher={Springer}
}

% not cited
@article{Kutschinski03,
  title={Learning competitive pricing strategies by multi-agent reinforcement learning},
  author={Kutschinski, Erich and Uthmann, Thomas and Polani, Daniel},
  journal={Journal of Economic Dynamics and Control},
  volume={27},
  number={11},
  pages={2207--2218},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{Zhu03,
  title={Semi-supervised learning using gaussian fields and harmonic functions},
  author={Zhu, Xiaojin and Ghahramani, Zoubin and Lafferty, John and others},
  booktitle={ICML},
  volume={3},
  pages={912--919},
  year={2003}
}

@inproceedings{Abbeel04,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004},
  organization={ACM}
}

@inproceedings{Morimoto04,
  title={A simple reinforcement learning algorithm for biped walking},
  author={Morimoto, Jun and Cheng, Gordon and Atkeson, Christopher G and Zeglin, Garth},
  booktitle={Robotics and Automation, 2004. Proceedings. ICRA'04. 2004 IEEE International Conference on},
  volume={3},
  pages={3030--3035},
  year={2004},
  organization={IEEE}
}

@inproceedings{Valko12,
  title={Semi-Supervised Apprenticeship Learning.},
  author={Valko, Michal and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
  booktitle={EWRL},
  pages={131--142},
  year={2012}
}

@article{Kober13,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  pages={0278364913495721},
  year={2013},
  publisher={SAGE Publications}
}

@inproceedings{Vasquez14,
  title={An open framework for human-like autonomous driving using Inverse Reinforcement Learning},
  author={Vasquez, Dizan and Yu, Yufeng and Kumar, Suryansh and Laugier, Christian},
  booktitle={2014 IEEE Vehicle Power and Propulsion Conference (VPPC)},
  pages={1--4},
  year={2014},
  organization={IEEE}
}

@inproceedings{Audiffren15,
  title={Maximum entropy semi-supervised inverse reinforcement learning},
  author={Audiffren, Julien and Valko, Michal and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2015}
}

@article{Mnih15,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{Shalev16,
  title={Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@article{Silver16,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{Finn17,
  title={Generalizing Skills with Semi-Supervised Reinforcement Learning},
  author={Finn, Chelsea and Yu, Tianhe and Fu, Justin and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1612.00429},
  year={2016}
}
